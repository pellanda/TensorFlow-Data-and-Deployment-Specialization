{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "C4_W3_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-2-public/blob/adding_C4/C4/W3/assignment/C4_W3_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn6uoicCMcDs"
      },
      "source": [
        "# TensorBoard with Fashion MNIST\n",
        "\n",
        "In this week's exercise you will train a convolutional neural network to classify images of the Fashion MNIST dataset and you will use TensorBoard to explore how it's confusion matrix evolves over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azqohJo2McDt"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5BRHr6bMcDt"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1R_jqNfMcDt"
      },
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV99LJ8hMcDt"
      },
      "source": [
        "import io\n",
        "import itertools\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mHJTPGhMcDv"
      },
      "source": [
        "## Load the Fashion-MNIST Dataset\n",
        "\n",
        "We are going to use a CNN to classify images in the the [Fashion-MNIST](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) dataset. This dataset consist of 70,000 grayscale images of fashion products from 10 categories, with 7,000 images per category. The images have a size of $28\\times28$ pixels.\n",
        "\n",
        "First, we load the data. Even though these are really images, we will load them as NumPy arrays and not as binary image objects. The data is already divided into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qH0-jieMcDw"
      },
      "source": [
        "# # Load the data.\n",
        "# ## run this if you are running the notebook on Coursera ############\n",
        "# train_images = np.load(f\"{getcwd()}/../tmp2/train_images.npy\")\n",
        "# train_labels = np.load(f\"{getcwd()}/../tmp2/train_labels.npy\")\n",
        "\n",
        "# test_images = np.load(f\"{getcwd()}/../tmp2/test_images.npy\")\n",
        "# test_labels = np.load(f\"{getcwd()}/../tmp2/test_labels.npy\")\n",
        "# ####################################################################\n",
        "\n",
        "# # Load the data.\n",
        "# ### run this if you are running the notebook on your local machine #######\n",
        "# train_images = np.load(\"./data/train_images.npy\")\n",
        "# train_labels = np.load(\"./data/train_labels.npy\")\n",
        "\n",
        "# test_images = np.load(\"./data/test_images.npy\")\n",
        "# test_labels = np.load(\"./data/test_labels.npy\")\n",
        "# ##########################################################################\n",
        "\n",
        "# Load the data.\n",
        "### run this if you are running the notebook on Colab #######\n",
        "!gdown --id 1GracLVtiZnC7JKq4B_WQSnsneus4E_LN\n",
        "train_images = np.load(\"/content/train_images.npy\")\n",
        "\n",
        "!gdown --id 1xulTlmt0G6ivfWZx3h1H2okyvGzWjG6W\n",
        "train_labels = np.load(\"/content/train_labels.npy\")\n",
        "\n",
        "!gdown --id 1jp8Z2ULuVkT3MAfMgohPE7koZ2nxu3J3\n",
        "test_images = np.load(\"/content/test_images.npy\")\n",
        "\n",
        "!gdown --id 1MFWfUWGBnbHXz6UVTjYyvI1YfWHPM6u6\n",
        "test_labels = np.load(\"/content/test_labels.npy\")\n",
        "##########################################################################\n",
        "\n",
        "# The labels of the images are integers representing classes.\n",
        "# Here we set the Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBhUIly8McDw"
      },
      "source": [
        "## Format the Images\n",
        "\n",
        "`train_images` is a NumPy array with shape `(60000, 28, 28)` and `test_images` is a NumPy array with shape `(10000, 28, 28)`. However, our model expects arrays with shape `(batch_size, height, width, channels)` . Therefore, we must reshape our NumPy arrays to also include the number of color channels. Since the images are grayscale, we will set `channels` to `1`. We will also normalize the values of our NumPy arrays to be in the range `[0,1]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOFdyt-qMcDx"
      },
      "source": [
        "# Pre-process images\n",
        "train_images = train_images.reshape(60000, 28, 28, 1)\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbyfN1E_McDx"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "We will build a simple CNN and compile it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jg68W8dMcDx"
      },
      "source": [
        "# Build the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZIJGB1McDy"
      },
      "source": [
        "## Plot Confusion Matrix\n",
        "\n",
        "When training a classifier, it's often useful to see the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix). The confusion matrix gives you detailed knowledge of how your classifier is performing on test data.\n",
        "\n",
        "In the cell below, we will define a function that returns a Matplotlib figure containing the plotted confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22GSmSIWMcDy"
      },
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "    \"\"\"\n",
        "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "    \n",
        "    Args:\n",
        "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "       class_names (array, shape = [n]): String names of the integer classes\n",
        "    \"\"\"\n",
        "    \n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    \n",
        "    # Normalize the confusion matrix.\n",
        "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    \n",
        "    # Use white text if squares are dark; otherwise black.\n",
        "    threshold = cm.max() / 2.\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asJYywvPMcDy"
      },
      "source": [
        "## TensorBoard Callback\n",
        "\n",
        "We are now ready to train the CNN and regularly log the confusion matrix during the process. In the cell below, you will create a [Keras TensorBoard callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) to log basic metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9ZAPuFqMcDz"
      },
      "source": [
        "# Clear logs prior to logging data.\n",
        "!rm -rf logs/image\n",
        "\n",
        "# Create log directory\n",
        "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# EXERCISE: Define a TensorBoard callback. Use the log_dir parameter\n",
        "# to specify the path to the directory where you want to save the\n",
        "# log files to be parsed by TensorBoard.\n",
        "tensorboard_callback = # YOUR CODE HERE\n",
        "\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3-T6AKzMcD0"
      },
      "source": [
        "## Convert Matplotlib Figure to PNG\n",
        "\n",
        "Unfortunately, the Matplotlib file format cannot be logged as an image, but the PNG file format can be logged. So, you will create a helper function that takes a Matplotlib figure and converts it to PNG format so it can be written. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulc9CODAMcD2"
      },
      "source": [
        "def plot_to_image(figure):\n",
        "    \"\"\"\n",
        "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\n",
        "    \"\"\"\n",
        "    \n",
        "    buf = io.BytesIO()\n",
        "    \n",
        "    # EXERCISE: Use plt.savefig to save the plot to a PNG in memory.\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    \n",
        "    # EXERCISE: Use tf.image.decode_png to convert the PNG buffer\n",
        "    # to a TF image. Make sure you use 4 channels.\n",
        "    image = # YOUR CODE HERE\n",
        "    \n",
        "    # EXERCISE: Use tf.expand_dims to add the batch dimension\n",
        "    image = # YOUR CODE HERE\n",
        "    \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZDwCMfdMcD4"
      },
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "In the cell below, you will define a function that calculates the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aye2vOPHMcD5"
      },
      "source": [
        "def log_confusion_matrix(epoch, logs):\n",
        "    \n",
        "    # EXERCISE: Use the model to predict the values from the test_images.\n",
        "    test_pred_raw = # YOUR CODE HERE\n",
        "    \n",
        "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "    \n",
        "    # EXERCISE: Calculate the confusion matrix using sklearn.metrics\n",
        "    cm = # YOUR CODE HERE\n",
        "    \n",
        "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "    cm_image = plot_to_image(figure)\n",
        "    \n",
        "    # Log the confusion matrix as an image summary.\n",
        "    with file_writer_cm.as_default():\n",
        "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "\n",
        "# Define the per-epoch callback.\n",
        "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlworharMcD5"
      },
      "source": [
        "## Run TensorBoard\n",
        "\n",
        "We are now ready to run the TensorBoard.\n",
        "\n",
        "**Note:** If the notebook doesn't render the TensorBoard, sometimes is due to the local host. If you are experiencing problems try adding the `--host localhost` option to the `tensorboard` magic:\n",
        "\n",
        "```python\n",
        "# Start TensorBoard\n",
        "%tensorboard --logdir logs/image --host localhost\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKqEP54RMcD6"
      },
      "source": [
        "# Start TensorBoard.\n",
        "%tensorboard --logdir logs/image \n",
        "\n",
        "# Train the classifier.\n",
        "model.fit(train_images,\n",
        "          train_labels,\n",
        "          epochs=5,\n",
        "          verbose=0, # Suppress chatty output\n",
        "          callbacks=[tensorboard_callback, cm_callback],\n",
        "          validation_data=(test_images, test_labels),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}